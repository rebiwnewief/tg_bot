{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_style_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RObXegH14S2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQv5MV6j4WLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhX-8peV5D0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, TVLoss_weight= 1):\n",
        "        super(TVLoss,self).__init__()\n",
        "        self.TVLoss_weight = TVLoss_weight\n",
        "\n",
        "    def forward(self,x):    \n",
        "        w_variance = torch.sum(torch.pow(x[:,:,:,:-1] - x[:,:,:,1:], 2))\n",
        "        h_variance = torch.sum(torch.pow(x[:,:,:-1,:] - x[:,:,1:,:], 2))\n",
        "        loss = self.TVLoss_weight * (h_variance + w_variance)\n",
        "        return loss\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "    \n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,in_features):\n",
        "        super(ResidualBlock,self).__init__()\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features)  ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x) #skip connection\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_nc, ngf=64):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        #Inital Conv Block\n",
        "        model = [   nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(in_nc, ngf, 7),\n",
        "                    nn.InstanceNorm2d(ngf),\n",
        "                    nn.ReLU(inplace=True) ]\n",
        "\n",
        "        in_features = ngf\n",
        "        out_features = in_features *2\n",
        "\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "            in_features = out_features\n",
        "            out_features = in_features * 2\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #Return batch w/ encoded content picture\n",
        "        return [self.model(x['content']), x['style_label']]\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,n_styles, ngf, auto_id=True):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.t = nn.ModuleList([ResidualBlock(ngf*4) for i in range(n_styles)])\n",
        "        if auto_id:\n",
        "            self.t.append(Identity())\n",
        "\n",
        "    def forward(self,x):\n",
        "        #x0 - конетент, x[1][0] - номер стиля\n",
        "        label = x[1][0]\n",
        "        mix = np.sum([self.t[i](x[0])*v for (i,v) in enumerate(label) if v])\n",
        "        return mix\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, out_nc, ngf, n_residual_blocks=5):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        in_features = ngf * 4\n",
        "        out_features = in_features//2\n",
        "\n",
        "        model = []\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        for _ in range(2):\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features//2\n",
        "\n",
        "        # Output layer\n",
        "        model += [  nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(64, out_nc, 7),\n",
        "                    nn.Tanh() ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,in_nc,out_nc,n_styles,ngf):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(in_nc,ngf)\n",
        "        self.transformer = Transformer(n_styles,ngf)\n",
        "        self.decoder = Decoder(out_nc,ngf)\n",
        "\n",
        "    def forward(self,x):\n",
        "        e = self.encoder(x)\n",
        "        t = self.transformer(e)\n",
        "        d = self.decoder(t)\n",
        "        return d\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Patch-Gan discriminator \n",
        "    \"\"\"\n",
        "    def __init__(self, in_nc, n_styles, ndf=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        model = [   nn.Conv2d(in_nc, 64, 4, stride=2, padding=2),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=2),\n",
        "                    nn.InstanceNorm2d(128),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=2),\n",
        "                    nn.InstanceNorm2d(256),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(256, 512, 4,stride=1, padding=2),\n",
        "                    nn.InstanceNorm2d(512),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "        # GAN (real/notreal) Output-\n",
        "        self.fldiscriminator = nn.Conv2d(512, 1, 4, padding = 2)\n",
        "\n",
        "        # Classification Output\n",
        "        self.aux_clf = nn.Conv2d(512, n_styles, 4, padding = 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        base =  self.model(x)\n",
        "        discrim = self.fldiscriminator(base)\n",
        "        clf = self.aux_clf(base).transpose(1,3)\n",
        "\n",
        "        return [discrim,clf]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAwL8DDO5E43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, mode='train'):\n",
        "        transforms_ = [ transforms.Resize(int(143), Image.BICUBIC), \n",
        "                transforms.RandomCrop(128), \n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) \n",
        "              ]\n",
        "        #content source\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.X = sorted(glob.glob(os.path.join(root, f'{mode}A', '*')))\n",
        "        \n",
        "        #style image source(s)\n",
        "        self.Y = []\n",
        "        style_sources = sorted(glob.glob(os.path.join(root, f'{mode}B', '*')))\n",
        "        for label,style in enumerate(style_sources):\n",
        "            temp = [(label,x) for x in sorted(glob.glob(style_sources[label]+\"/*\"))]\n",
        "            self.Y.extend(temp)\n",
        "        \n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "                                                 \n",
        "        output = {}\n",
        "        output['content'] = self.transform(Image.open(self.X[index % len(self.X)]))\n",
        "        \n",
        "        #select style\n",
        "        selection = self.Y[random.randint(0, len(self.Y) - 1)]\n",
        "        \n",
        "        try:                                         \n",
        "            output['style'] = self.transform(Image.open(selection[1]))\n",
        "        except:\n",
        "            print('Серый')\n",
        "            print(selection)\n",
        "                        \n",
        "        output['style_label'] = selection[0]\n",
        "    \n",
        "        return output\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(len(self.X), len(self.Y))\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB9yG2YNJIAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label2tensor(label,tensor):\n",
        "    for i in range(label.size(0)):\n",
        "        tensor[i].fill_(label[i])\n",
        "    return tensor\n",
        "\n",
        "def tensor2image(tensor):\n",
        "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
        "    if image.shape[0] == 1:\n",
        "        image = np.tile(image, (3,1,1))\n",
        "    return image.astype(np.uint8)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbLBigKr4rqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRAIN OPTIONS FROM GATED GAN\n",
        "epoch = 0\n",
        "n_epochs = 200\n",
        "decay_epoch=100\n",
        "batchSize = 1\n",
        "dataroot = '/content/drive/My Drive/Colab Notebooks/photo2fourcollection'\n",
        "loadSize = 143\n",
        "fineSize = 128\n",
        "ngf = 64\n",
        "ndf = 64    \n",
        "in_nc = 3 \n",
        "out_nc = 3 \n",
        "lr = 0.0002 \n",
        "gpu = 1 \n",
        "lambda_A = 10.0\n",
        "pool_size = 50\n",
        "resize_or_crop = 'resize_and_crop'\n",
        "autoencoder_constrain = 10 \n",
        "n_styles = 4\n",
        "cuda=True\n",
        "tv_strength=1e-6"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nguo356Q4r8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4017b9a7-d6e6-423a-f69b-0f1061f35acf"
      },
      "source": [
        "dataloader = DataLoader(ImageDataset('/content/drive/My Drive/Colab Notebooks/photo2fourcollection'), \n",
        "                        batch_size=1, shuffle=True, num_workers=4)\n",
        "\n",
        "batch = next(iter(dataloader))\n",
        "\n",
        "batch['style_label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pvNTTZC40Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator(in_nc, out_nc, n_styles, ngf)\n",
        "discriminator = Discriminator(in_nc, n_styles, ndf)\n",
        "\n",
        "#generator.load_state_dict(torch.load('./output/netG.pth'))\n",
        "\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLovHeRM68vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Losses Init\n",
        "use_lsgan=True\n",
        "if use_lsgan:\n",
        "    criterion_GAN = nn.MSELoss()\n",
        "else: \n",
        "    criterion_GAN = nn.BCELoss()\n",
        "    \n",
        "    \n",
        "criterion_ACGAN = nn.CrossEntropyLoss()\n",
        "criterion_Rec = nn.L1Loss()\n",
        "criterion_TV = TVLoss(TVLoss_weight=tv_strength)\n",
        "\n",
        "\n",
        "#Optimizers & LR schedulers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(),\n",
        "                                lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), \n",
        "                               lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "class LambdaLR():\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "        \n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch,decay_epoch).step)\n",
        "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(n_epochs,epoch, decay_epoch).step)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFPlgL7M7BA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74c75569-4d76-4fdf-c7f7-4b87fd4737de"
      },
      "source": [
        "#Set vars for training\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "input_A = Tensor(batchSize, in_nc, fineSize, fineSize)\n",
        "input_B = Tensor(batchSize, out_nc, fineSize, fineSize)\n",
        "target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
        "target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
        "\n",
        "D_A_size = discriminator(input_A.copy_(batch['style']))[0].size()  \n",
        "D_AC_size = discriminator(input_B.copy_(batch['style']))[1].size()\n",
        "\n",
        "class_label_B = Tensor(D_AC_size[0],D_AC_size[1],D_AC_size[2]).long()\n",
        "\n",
        "autoflag_OHE = Tensor(1,n_styles+1).fill_(0).long()\n",
        "autoflag_OHE[0][-1] = 1\n",
        "\n",
        "fake_label = Tensor(D_A_size).fill_(0.0)\n",
        "real_label = Tensor(D_A_size).fill_(0.99) \n",
        "\n",
        "rec_A_AE = Tensor(batchSize,in_nc,fineSize,fineSize)\n",
        "\n",
        "fake_buffer = ReplayBuffer()\n",
        "\n",
        "##Init Weights\n",
        "generator.apply(weights_init_normal)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (encoder): Encoder(\n",
              "    (model): Sequential(\n",
              "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
              "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (9): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (t): ModuleList(\n",
              "      (0): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (1): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (2): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (3): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Identity()\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (model): Sequential(\n",
              "      (0): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (1): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (2): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (3): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (4): ResidualBlock(\n",
              "        (conv_block): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "          (3): ReLU(inplace=True)\n",
              "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        )\n",
              "      )\n",
              "      (5): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "      (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (7): ReLU(inplace=True)\n",
              "      (8): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "      (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (10): ReLU(inplace=True)\n",
              "      (11): ReflectionPad2d((3, 3, 3, 3))\n",
              "      (12): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
              "      (13): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-cZoGTB7i3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "d750e561-8a97-455b-d4a9-21a825fc2415"
      },
      "source": [
        "discriminator.apply(weights_init_normal)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
              "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (fldiscriminator): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
              "  (aux_clf): Conv2d(512, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRbFMgkl7rRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = Logger(n_epochs, len(dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0F4K9uW7uSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "a0246ef9-c36c-449f-8cae-4b8cbc1baa10"
      },
      "source": [
        "### TRAIN LOOP\n",
        "for epoch in tqdm(range(epoch,n_epochs - 1)):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # если картинка серая, то пропускаем ее\n",
        "        if len(batch) == 2:\n",
        "          continue\n",
        "        real_content = Variable(input_A.copy_(batch['content']))\n",
        "        # target style\n",
        "        real_style = Variable(input_B.copy_(batch['style']))\n",
        "        # style label\n",
        "        style_label = batch['style_label']\n",
        "        # one-hot encoded style\n",
        "        style_OHE = F.one_hot(style_label,n_styles).long()\n",
        "        # номер стиля расширенный до 1x19x19 для дискриминатора\n",
        "        class_label = class_label_B.copy_(label2tensor(style_label,class_label_B)).long()\n",
        "        \n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        \n",
        "        # Generate style-transfered image\n",
        "        genfake = generator({\n",
        "            'content':real_content,\n",
        "            'style_label': style_OHE})\n",
        "        \n",
        "        fake = fake_buffer.push_and_pop(genfake)\n",
        "        # Дискриминатор с фейком\n",
        "        out_gan, out_class = discriminator(fake)\n",
        "        errD_fake = criterion_GAN(out_gan, fake_label)\n",
        "        errD_fake.backward()\n",
        "        optimizer_D.step()\n",
        "        \n",
        "        optimizer_D.zero_grad()\n",
        "        # Дискриминатор с реальным изображением\n",
        "        out_gan, out_class = discriminator(real_style)\n",
        "        errD_real_class = criterion_ACGAN(out_class.transpose(1,3),class_label)*lambda_A\n",
        "        errD_real = criterion_GAN(out_gan, real_label)        \n",
        "        errD_real_total = errD_real + errD_real_class\n",
        "        errD_real_total.backward()\n",
        "        optimizer_D.step()\n",
        "        \n",
        "        \n",
        "        errD = (errD_real+errD_fake)/2.0\n",
        "        \n",
        "                \n",
        "\n",
        "        # Генератор \n",
        "        optimizer_G.zero_grad()\n",
        "        \n",
        "        # Дискриминатор с генерированным фейком\n",
        "        out_gan, out_class = discriminator(genfake)\n",
        "        \n",
        "        err_gan = criterion_GAN(out_gan, real_label)\n",
        "        err_class = criterion_ACGAN(out_class.transpose(1,3), class_label)*lambda_A\n",
        "        err_TV = criterion_TV(genfake)\n",
        "        \n",
        "        errG_tot = err_gan + err_class + err_TV \n",
        "        \n",
        "        errG_tot.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        ## Auto-Encoder (Recreation) Loss\n",
        "        optimizer_G.zero_grad()\n",
        "        identity = generator({\n",
        "            'content': real_content,\n",
        "            'style_label': autoflag_OHE,\n",
        "        })\n",
        "        err_ae = criterion_Rec(identity,real_content)*autoencoder_constrain\n",
        "        err_ae.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        \n",
        "\n",
        "    \n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D.step()\n",
        "    \n",
        "    #Save model\n",
        "    torch.save(generator.state_dict(), '/content/drive/My Drive/stepik/netG1.pth')\n",
        "    torch.save(discriminator.state_dict(), '/content/drive/My Drive/stepik/netD1.pth')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/199 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f1b9211a3d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### TRAIN LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# если картинка серая, то пропускаем ее\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "thisuns grey\n",
            "(2, '/content/drive/My Drive/Colab Notebooks/photo2fourcollection/trainB/ukiyoe/00688.jpg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHh4GIH84Ttm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjOVo0434Twf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}